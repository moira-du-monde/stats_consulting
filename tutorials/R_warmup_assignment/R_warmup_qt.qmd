---
title: "R_warmup_assignment"
author: "Moira"
format: html
editor: visual
---

NOTE: Use base R except where instructed otherwise.

## Q1.

What version of R are you using?

```{r}
sessionInfo()

Sys.info()

devtools::session_info()
```

## Q2.

Import csv or txt files using base R (data files available in Github Repo).

After importing the data frame, run it through the functions str() and summary(). What are these showing you?

```{r}
args(read.csv)
```

```{r}
df <- read.csv('https://raw.githubusercontent.com/moira-du-monde/stats_consulting/main/tutorials/Sample_Dataset_2019.csv', header = T, na.strings=c('','NA'), stringsAsFactors = TRUE)
 
str(df) # output is a table with variable names and their data types (e.g., int, num, chr)

summary(df) # for integer and number variables, output is the min, max, median, mean, 25th and 75th percentiles, and number of NAs

```

How many missing values are there for variable State?

```{r}
# can just refer to the printed summary, but this code works too:

sum(is.na(df$State))
```

## Q3.

Import csv using readr::read_csv. Which function did you use to do this?

```{r}
library(readr) # versus readr::read_csv, latter used to load single internal function

args(read_csv) #no stringsasfactors arg, so convert with added step base R

df <- read_csv('https://raw.githubusercontent.com/moira-du-monde/stats_consulting/main/tutorials/Sample_Dataset_2019.csv', na=c('','NA'))

df$State <- factor(df$State)

# Can also use dplyr to accomplish this:

# library(dplyr) # load dplyr
# 
# df <- df %>% 
#    mutate_if(is.character, factor) #convert strings to factors
head(df)
```

After importing the data frame, run it through the functions str() and summary(). What are these showing you?

```{r}

str(df) # also shows data type of each variable, in this case numbers, factors, dates, and 'hms' num

summary(df) # min, max, median, mean, 25th, 75th percentiles, # of NAs

```

How do the results of str() and summary() compare to the data frame you imported with read.csv? Dates are converted from characters to date times and factored, other characters are factored and summed

How many missing values are there for variable State?

\>\> Just use the output from the factored summary to check number of NaNs for State (26).

## Q4.

Import the SPSS \*.sav data file using haven::read_spss(). After importing the data frame, run it through the functions str() and summary().

What are these showing you?

```{r}
df_spss <- haven::read_spss("C:/Users/Moira/Downloads/Sample_Dataset_2019.sav")

str(df_spss) # summary hashable format.spss document with each variable's data type

summary(df_spss) # min, max, mean, median, 25th and 75th percentiles, number of NAs for numerical vars
```

How do the results of str() and summary() compare to the data frame you imported with read.csv and readr::read_csv()?

\>\> The dates and generic string values are characters by default. Also the package is importing the data as a tibble, which is a really crude kind of dataframe.

## Q5.

Import the Excel \*.xlsx data file using readxl::read_excel(). After importing the data frame, run it through the functions str() and summary().

What are these showing you?

\>\> Basically shows same descriptive statistics as before.

```{r}
df_xl <- readxl::read_excel("C:/Users/Moira/Downloads/Sample_Dataset_2019.xlsx")

str(df_xl)

summary(df_xl)
```

How do the results of str() and summary() compare to the data frame you imported with read.csv, readr::read_csv(), and haven::read_spss()?

\>\> Similar to importing with base R (w/ default stringsAsFactors = FALSE), but data types are numbers, characters, and "POSIXct" (which rep. calendar dates and time).

## Q6.

Create a frequency table for variable State. Create a frequency table that explicitly shows the number of missing values.

How would you add marginal frequencies (i.e., row/column totals) to the table?

```{r}
df <- read.csv('https://raw.githubusercontent.com/moira-du-monde/stats_consulting/main/tutorials/Sample_Dataset_2019.csv', header = T, na.strings=c('','NA'), stringsAsFactors = TRUE)

# alt for default stringsAsFactors = FALSE

# df <- df %>% 
#   mutate_if(is.character, factor)

mytable <- table(df$State, exclude = "no")

# alt : df_table <- table(df$State,useNA="always")

mytable <- list(margin.table(mytable))


mytable


# alt:

#if table was higher dimensions (i.e. >= 2), could just use colSums and rowSums...but in this case it throws an error

# mytable_ttl <- rbind(mytable, colSums(mytable), rowSums(mytable))

```

How would you display the proportions for this table? (Note: you do not need to have the frequencies and proportions printed side-by-side to answer this question).

```{r}
df_table <- table(df$State,useNA="always")

df_table$prop <- c(prop.table(df_table))

df_table
```

## Q7.

Create a frequency table for variable Rank.

Create a frequency table for the variable Rank. Notice that it prints the data values 1, 2, 3, 4.

Like SAS, SPSS, and Stata, R has the ability to assign labels to numeric values (R treats these as a special type(s) of variable) and treat the resulting variables as nominal or ordinal. What base R function(s) do this? \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

After finding and applying the base R function(s) to assign labels to the numeric values, rerun the frequency table.

```{r}
rank_data <- table(df$Rank, exclude = "no")

rank_data

#use factor() function for nominal data

# use ordered() function for ordinal data
df$desc <- ordered(df$Rank,
                   levels = c(1,2,3,4),
                   labels = c("Below 25th", "Above 25th", "Above 50th", "Above 75th"))
table(df$desc)
```

## Q8.

Compute BMI from weight (in pounds) and height (in inches) as a new variable in your dataframe.

Compute a new variable categorizing the numeric BMI values into ranges (can use the CDC guidelines to determine cutpoints) as a new variable in your dataframe.

Tabulate the new variable from step B and get proportions.

```{r}

df$BMI <- df$Weight / (df$Height * df$Height)*703

# alt w dplyr

# df <- df %>%
#   mutate(BMI = df$Weight / (df$Height * df$Height)*703)


summary(df)

```

Compute a new variable categorizing the numeric BMI values into ranges (can use the CDC guidelines to determine cutpoints) as a new variable in your dataframe.

```{r}

# na.omit(df)
# 
# overweight <- df[df$BMI >= 25,]

ovwt <- length(which(df$BMI >= 25))

# alt w dplyr:
# overweight <- df %>%
#   filter(BMI > 25)

# count(overweight)

bmi_nan <- sum(is.na(df$BMI))

perc_overweight <- ovwt / ( 435 - bmi_nan )
perc_overweight

```

Tabulate the new variable from step B and get proportions.

```{r}


df$category <- cut(df$BMI,breaks = c(0, 18.5,25,30,50),labels = c("underweight", "healthy","overweight", "obese"))

df_cat <- table(df$category)

na.omit(df_cat)

df_cat$prop <- c(prop.table(df_cat))

df_cat

```

## Q9.

Obtain descriptive statistics (mean/sd/confidence intervals, possibly by groups, and Pearson correlations; OR frequency tables/crosstabs/proportions) for the following sets/pairs of variables. (Note: The appropriate responses will not be ones that have all NA values)

*Height and Weight*

```{r}


cor.test(df$Height, df$Weight) #pearson as default
```

*English, Reading, Math, Science*

```{r}

eng <- df$English
reading <- df$Reading
math <- df$Math
science <- df$Science

additive <- aov(reading ~ eng + math*science)

summary(additive)

interactions <- aov(reading ~ eng*math*science)

summary(interactions)
```

*Mile and Athlete Y/N*

```{r}

df$dist <- cut(df$Mile,breaks = c(301.0, 401.0, 463.0, 558.0, 896.0),labels = c("lower quartile", "lower-middle quartile","upper-middle quartile", "upper quartile"))

mile_athlete <- xtabs(~df$dist+df$Athlete)

ftable(mile_athlete)

```

State and LiveOnCampus

```{r}

state_campus <- xtabs(~df$State+df$LiveOnCampus)

ftable(state_campus)

summary(state_campus)
```

LiveOnCampus, HowCommute, CommuteTime

```{r}
summary(df$CommuteTime)

df$commute_cat <- cut(df$CommuteTime,breaks = c(2.00, 18.00, 25.00, 30.00, 43.00),labels = c("lower quartile", "lower-middle quartile","upper-middle quartile", "upper quartile"))

three <- table(df$commute_cat,df$LiveOnCampus,df$HowCommute)
three
```

## Q10.

What is the Cronbach's alpha for the extraversion scale? (Note: There isn't a Cronbach's alpha function in base R, as far as I know; there is one in package psych)

Check if any of the items need to be reverse-coded before doing this.

After obtaining the Cronbach's alpha value, compute a new variable containing the subjects' composite scores by averaging their responses to the Likert items. Note: Simply using the mean() function alone will not achieve this.

```{r}

```

## Q11.

If you do a linear regression of SleepTime (Y) on StudyTime (X), are the assumptions of linear regression met? (Linear relationship, Multivariate normality, No or little multicollinearity, No auto-correlation, Homoscedasticity)

\>\>

What is the base R function to run a linear regression?

```{r}

df <- read.csv('https://raw.githubusercontent.com/moira-du-monde/stats_consulting/main/tutorials/Sample_Dataset_2019.csv', header = T, na.strings=c('','NA'), stringsAsFactors = TRUE)
# 
# df <- df %>% 
#   mutate_if(is.character, factor)

linearmodel <- lm(df$SleepTime ~ df$StudyTime)

```

How can you print the "classic" table of regression parameter estimates, t-statistics, p-values from this linear regression?

```{r}

summary(linearmodel)
```

How can you plot the residuals from this linear regression?

```{r}

linearmodel.lm = lm(df$SleepTime ~ df$StudyTime)
linearmod.res = resid(linearmodel.lm)

mod <- predict(linearmodel.lm)
plot(mod,linearmod.res,
     ylab = "resid", xlab = "pred")
abline(0,0)
```

Re-do the linear regression after mean-centering the independent variable.

```{r}

df <- na.omit(df)

summary(df$StudyTime)

df$st <- df$StudyTime - mean(df$StudyTime)

# df <- df %>%
#   mutate(st = df$StudyTime - mean(df$StudyTime))
# summary(df$st)

linearmodel.lm = lm(df$SleepTime ~ df$st)
linearmod.res = resid(linearmodel.lm)


mod <- predict(linearmodel.lm)
plot(mod,linearmod.res,
     ylab = "resid", xlab = "pred")
abline(0,0)
```

## Q12.

If you do a linear regression of SleepTime (Y) on StudyTime and Rank (X), are the assumptions of linear regression met? (Linear relationship, Multivariate normality, No or little multicollinearity, No auto-correlation, Homoscedasticity)

\>\>

Run the model with Rank as a numeric variable. What terms are in the model?

```{r}

df <- read.csv('https://raw.githubusercontent.com/moira-du-monde/stats_consulting/main/tutorials/Sample_Dataset_2019.csv', header = T, na.strings=c('','NA'), stringsAsFactors = TRUE)

# df <- df %>% 
#   mutate_if(is.character, factor)

fit <- lm(df$SleepTime ~ df$StudyTime + df$Rank)

summary(fit)
```

Run the model with Rank as an "ordered" variable. What terms are in the model?

```{r}

# use ordered() function for ordinal data
df$desc <- ordered(df$Rank,
                   levels = c(1,2,3,4))

ord <- lm(df$SleepTime ~ df$StudyTime + df$desc)

summary(ord)
```

Run the model with Rank as a "factor" variable. What terms are in the model?

```{r}
#use factor() function for nominal data

# use ordered() function for ordinal data
df$fac <- factor(df$Rank)

fac <- lm(df$SleepTime ~ df$StudyTime + df$fac)

summary(fac)
```

What are the differences between these 3 approaches?

\>\>

Re-do the regression after group-mean centering variable StudyTime about the means of the class rank groups.

```{r}

df <- read.csv('https://raw.githubusercontent.com/moira-du-monde/stats_consulting/main/tutorials/Sample_Dataset_2019.csv', header = T, na.strings=c('','NA'), stringsAsFactors = TRUE)

df$Rank <- ordered(df$Rank,
                   levels = c(1,2,3,4))

group_mean <- aggregate(StudyTime ~ Rank, data = df, mean)

group_mean

r_1 <- df[df$Rank == 1,]
r_1$StudyTime <- r_1$StudyTime - 4.791667

r_2 <- df[df$Rank == 2,]
r_2$StudyTime <- r_2$StudyTime - 6.028302

r_3 <- df[df$Rank == 3,]
r_3$StudyTime <- r_3$StudyTime - 9.210526

r_4 <- df[df$Rank == 4,]
r_4$StudyTime <- r_4$StudyTime - 14.138889

ranked <- rbind(r_1, r_2, r_3, r_4)

fit_rank <- lm(ranked$SleepTime ~ ranked$StudyTime + ranked$Rank)

summary(fit_rank)
```

```{r}
# if (df$Rank == 1) {df$st_adj <- df$StudyTime - 4.791667
# } else if (df$Rank == 2) {df$adj_st <- df$StudyTime - 6.028302
# } else if (df$Rank == 3) {df$adj_st <- df$StudyTime - 9.210526
# } else {df$adj_st <- df$StudyTime - 14.138889}
```
